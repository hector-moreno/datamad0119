{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Título del proyecto\n",
    "\n",
    "'''\n",
    "\n",
    "Shark adventures: ¿Quieres sentir la adrenalina de nadar con tiburones?\n",
    "\n",
    "'''\n",
    "\n",
    "# Objetivo del proyecto\n",
    "\n",
    "'''\n",
    "La empresa Extreme quiere lanzar una nueva actividad: experiencias de riesgo con tiburones y pretende:\n",
    "-Definir el target: edad y sexo.\n",
    "-Limitar la región para el lanzamiento del producto.\n",
    "-Localizar un parámetro que conlleve el ataque de tiburones.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realizamos la importaciones que necesitaremos a lo largo del proyecto\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos el archivo csv\n",
    "\n",
    "dataoriginal = pd.read_csv('GSAF5.csv', encoding = \"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guía de trabajo del proyecto\n",
    "'''\n",
    "El presente archivo implementa las siguientes técnicas:\n",
    "\n",
    "* Eliminación de **registros duplicados** \n",
    "\n",
    "* **Examen** de los datos y **comprensión** de sus campos.\n",
    "\n",
    "* **Selección** de la información relevante y eliminación de la no pertinente mediante la reducción \n",
    "de columnas presentes de en el data frame.\n",
    "\n",
    "* **Cambio de nombre de columnas** por nombres más informativo y que conlleven menos problemas \n",
    "a la hora de trabajar la información.\n",
    "\n",
    "* **Cambio de nombre de columnas** en función de los objetivos del proyecto.\n",
    "\n",
    "* Elección y creación de **subset objeto de estudio**.\n",
    "\n",
    "* Análisis del peso de los **valores nulos** en nuestros datos y actuaciones \n",
    "en función de las conclusiones: eliminación de columnas y sustitución de los mismos.\n",
    "\n",
    "* Corrección de **valores incorrectos**.\n",
    "\n",
    "* Prevención de presencia de columnas con **low variance**\n",
    "\n",
    "* Modificaciones de **strings**.\n",
    "\n",
    "* Corrección de **data types**\n",
    "\n",
    "* Realización de **Custom-sized bins**\n",
    "\n",
    "* Obtención de conclusiones tras el estudio a través de funciones.\n",
    "\n",
    "* Combinación de subsets: **merge** y **melt**\n",
    "\n",
    "* Exportación de los datos a **.csv**.\n",
    "\n",
    "\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comenzamos con una perspectiva visual del dataset.\n",
    "\n",
    "dataoriginal.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encontramos y eliminamos registros duplicados\n",
    "\n",
    "before = len(dataoriginal)\n",
    "data = dataoriginal.drop_duplicates()\n",
    "after = len(dataoriginal)\n",
    "print('Number of duplicate records dropped: ', str(before - after))\n",
    "\n",
    "# En primera instancia data no presenta registros duplicados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selección de columnas\n",
    "\n",
    "''' Reducimos data seleccionando solo las columnas interesantes en un nuevo DataFrame: data.\n",
    "Descartamos: Name, pdf, href formula, href, case number 1, Case numer 2, Unnamed 23, Unnamed 22.\n",
    "Las columnas descartadas no presentan información pertinente para los objetivos del proyecto.\n",
    "'''\n",
    "col_seleccion = ['Case Number', 'Date', 'Year', 'Type', 'Country', 'Area', 'Location',\n",
    "                 'Activity', 'Sex ', 'Age', 'Injury', 'Fatal (Y/N)', 'Time', 'Species ']\n",
    "data = dataoriginal[col_seleccion]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cambio de nombre de columnas.\n",
    "\n",
    "'''\n",
    "Modificacción por títulos más informativos y menos conflictivos \n",
    "a la hora de trabajar con la información.\n",
    "'''\n",
    "\n",
    "data.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Cambiamos los nombres de las siguientes columnas:\n",
    "\n",
    "'Case number':'Case',\n",
    "'Sex ':'Sex'\n",
    "'Fatal (Y/N)': 'Fatal'\n",
    "'Species ': 'Sepecies'\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "data = data.rename(columns={'Case number':'Case',\n",
    "                            'Sex ':'Sex',\n",
    "                            'Fatal (Y/N)': 'Fatal',\n",
    "                            'Species ' :'Species'})\n",
    "\n",
    "data.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cambiando el orden de las columnas\n",
    "\n",
    "'''\n",
    "Cambiamos el orden de las columnas en función del objetivo del proyecto: localizar\n",
    "las zonas geográficas con los tiburones más peligrosos para vender baños de alto riesgo a los \n",
    "amantes de la adrenalina.\n",
    "'''\n",
    "\n",
    "column_order = ['Case Number', 'Fatal', 'Injury', 'Type', 'Activity', 'Sex', 'Age',  'Date', 'Year',  \n",
    "                'Country', 'Area', 'Location', 'Time', 'Species']\n",
    "\n",
    "data = data[column_order]\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Country'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elección y creación de subset objeto de estudio\n",
    "\n",
    "# Comprobamos qué valores pueden contener las columnas 'Year' y 'Cuntry'\n",
    "\n",
    "data['Year'].unique() \n",
    "data['Country'].unique() \n",
    "\n",
    "# Comprobamos en qué años y países se dan más ataque\n",
    "\n",
    "data['Country'].value_counts()\n",
    "data['Year'].value_counts()\n",
    "\n",
    "# Realizamos el filtrado\n",
    "\n",
    "'''Seleccionamos los casos de los últimos 30 años, para tomar decisiones a partir de información actualizada, \n",
    "y los países con mayor concentración de casos, es decir, más de 360'''\n",
    "\n",
    "filtered = data[(data['Year']>= 1998) & \n",
    "                ((data['Country'] == 'USA') | (data['Country'] == 'AUSTRALIA') | (data['Country'] == 'SOUTH AFRICA'))]\n",
    "\n",
    "filtered.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered.Type.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Nos interesa conocer las causas del ataques: humanas o naturales.\n",
    "Para ello creamos una columna 'Cause' categorías significativas: natural, artificial o unknown'''\n",
    "\n",
    "filtered.loc[filtered['Type'].str.startswith('U'), 'Cause'] = 'Natural'\n",
    "filtered.loc[filtered['Type'].str.startswith('P'), 'Cause'] = 'Artificial'\n",
    "filtered.loc[filtered['Type'].str.startswith('I'), 'Cause'] = 'Unknown'\n",
    "filtered.loc[filtered['Type'].str.startswith('B'), 'Cause'] = 'Unknown'\n",
    "filtered.loc[filtered['Type'].str.startswith('S'), 'Cause'] = 'Unknown'\n",
    "filtered.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analizammos el peso de los valores nulos en nuestros datos\n",
    "\n",
    "null_cols = filtered.isnull().sum()\n",
    "null_cols[null_cols > 0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Por la preponderancia de su valores nulos y la escasa aportación al estudio eliminamos la columna 'Species'\n",
    "\n",
    "drop_cols = list(null_cols[null_cols > 400].index)\n",
    "filtered = filtered.drop(drop_cols, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'Fatal' e 'Injury' tienen un valor nulo, veamos qué ha ocurrido.\n",
    "\n",
    "null_displ = filtered[(filtered['Fatal'].isnull()==True)]\n",
    "null_displ = null_displ[['Injury', 'Activity', 'Sex', 'Age', 'Area','Location','Time']]\n",
    "null_displ['Injury']\n",
    "\n",
    "# Observamos que dicho valor de fatal debería ser 'N', lo cambiamos.\n",
    "\n",
    "filtered[(filtered['Fatal'].isnull()==True)] = 'N'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_displ = filtered[(filtered['Injury'].isnull()==True)]\n",
    "null_displ = null_displ[['Injury', 'Fatal', 'Activity', 'Sex', 'Age', 'Area','Location','Time']]\n",
    "null_displ\n",
    "\n",
    "# Por sus registros dicho record debe ser eliminado\n",
    "filtered = filtered.drop(filtered[(filtered['Injury'].isnull()==True)].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' El resto de valores nulos los sustituimos por ceros, \n",
    "excepto en Age y Time que sustituimos por -1 para evitar errores de interpretación.'''\n",
    "\n",
    "filtered[['Activity', 'Sex', 'Area', 'Location']].fillna(0)\n",
    "filtered[['Age', 'Time']].fillna(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered.Fatal.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evitamos valores incorrectos, estableciendo que en accidentes fatales, Injury marque High\n",
    "\n",
    "filtered.loc[(filtered['Fatal']== 'Y') & (filtered['Injury']!= 'No injury'), 'Injury'] = 'High'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprobamos que no hay columnas con low variance\n",
    "\n",
    "low_variance = []\n",
    "\n",
    "for col in filtered._get_numeric_data():\n",
    "    minimum = min(filtered[col])\n",
    "    ninety_perc = np.percentile(filtered[col], 90)\n",
    "    if ninety_perc == minimum:\n",
    "        low_variance.append(col)\n",
    "low_variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Moficación de strings para poder realiza astype()\n",
    "'''Primero preparamos los datos para poder usar .astype()'''\n",
    "\n",
    "filtered['Age'] = filtered['Age'].fillna('-1')\n",
    "filtered['Age'] = filtered['Age'].str.replace('\\xa0 ', '-1')\n",
    "filtered['Age'] = filtered['Age'].str.replace('Teens', '14')\n",
    "filtered['Age'] = filtered['Age'].str.replace('36 & 26', '30')\n",
    "filtered['Age'] = filtered['Age'].str.replace('50s', '55')\n",
    "filtered['Age'] = filtered['Age'].str.replace('40s', '45')\n",
    "filtered['Age'] = filtered['Age'].str.replace('50s', '55')\n",
    "filtered['Age'] = filtered['Age'].str.replace('30s', '35')\n",
    "filtered['Age'] = filtered['Age'].str.replace('60s', '65')\n",
    "filtered['Age'] = filtered['Age'].str.replace('mid-30s', '35')\n",
    "filtered['Age'] = filtered['Age'].str.replace('8 or 10', '9')\n",
    "filtered['Age'] = filtered['Age'].str.replace('6œ', '-1')\n",
    "filtered['Age'] = filtered['Age'].str.replace('20s', '25')\n",
    "filtered['Age'] = filtered['Age'].str.replace('12 or 13', '12')\n",
    "filtered['Age'] = filtered['Age'].str.replace('33 or 37', '35')\n",
    "filtered['Age'] = filtered['Age'].str.replace('30 or 36', '33')\n",
    "filtered['Age'] = filtered['Age'].str.replace('teen', '14')\n",
    "filtered['Age'] = filtered['Age'].str.replace('Teen', '14')\n",
    "filtered['Age'] = filtered['Age'].str.replace('23 & 20', '21')\n",
    "filtered['Age'] = filtered['Age'].str.replace('N', '-1')\n",
    "filtered['Age'] = filtered['Age'].str.replace('mid-35', '35')\n",
    "print(set(filtered['Age']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data type correction de Age para poder hacer bins\n",
    "\n",
    "'''Aplicamos .astype()'''\n",
    "\n",
    "filtered['Age'] = filtered['Age'].astype('int')\n",
    "filtered.dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Realizamos un Custom-sized bins para 'Age'\n",
    "\n",
    "\n",
    "mpg_labels = ['Unknown','Young','Adult','Old']\n",
    "cutoffs = [-10,-1,20,60,90]\n",
    "bins = pd.cut(filtered['Age'],cutoffs, labels=mpg_labels)\n",
    "bins.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "filtered.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conclusiones:\n",
    "\n",
    "filtered['Country'].value_counts()\n",
    "\n",
    "\"\"\"\n",
    "En los últimos 30 años USA es el país con mayor número de casos:\n",
    "USA             986\n",
    "AUSTRALIA       345\n",
    "SOUTH AFRICA    148\n",
    "\"\"\"\n",
    "\n",
    "filtered[(filtered['Country']== 'USA')].Area.value_counts()\n",
    "\n",
    "\"\"\"\n",
    "La experiencia piloto de nuestros baños extremos las realizaremos en Florida y Hawai, pues son las áreas\n",
    "que mayor número de casos acumula:\n",
    "Florida              538\n",
    "Hawaii               122\n",
    "\"\"\"\n",
    "\n",
    "(filtered['Sex']== 'M').sum()\n",
    "(filtered['Sex']== 'F').sum()\n",
    "\n",
    "'''\n",
    "1174 ataques a hombres frente 240 a mujeres.\n",
    "Debemos dirigir nuestro producto a hombres.\n",
    "'''\n",
    "\n",
    "filtered['Age'].mean()\n",
    "\n",
    "bins.value_counts().max()\n",
    "\n",
    "'''La edad media de los atacados 22.39 unido  unido a a que la categoría de edad  con \n",
    "mayor concentración de ataque es old, nos hace dirigir el producto al intervalo de \n",
    "edades comprendido entre los 20 y los 60 años'''\n",
    "\n",
    "filtered['Activity'].value_counts()\n",
    "\n",
    "'''Además la actividad en concreto que debemos fomentar es el surf frent al simple nado.\n",
    "El surf es la actividad que mayor número de ataques aglutina. A mucha distancia de la segunda, el nado:\n",
    "Surfing                                        532\n",
    "Swimming                                       182\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combinación de subsets: merge\n",
    "\n",
    "'''\n",
    "Contrastamos país y edad media para comprobar nuestra conclusiones\n",
    "'''\n",
    "\n",
    "avg_age = filtered.groupby('Country', as_index=False).agg({'Age':'mean'})\n",
    "\n",
    "avg_age.columns = ['Country', 'Age']\n",
    "\n",
    "merged = pd.merge(filtered, avg_age, on='Country')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combinación de subset: agrupando por variable\n",
    "\n",
    "'''\n",
    "Para visualizar nuestras conclusiones obtenemos un data frame con los ataques producidos en américa\n",
    "\n",
    "y le realizamos un .merge() con las columnas de interés.\n",
    "\n",
    "'''\n",
    "\n",
    "df_usa = filtered[(filtered['Country']== 'USA')]\n",
    "melted = pd.melt(df_usa, id_vars=['Country','Area','Time'], \n",
    "                 value_vars=['Sex','Date','Activity'])\n",
    "melted.head(10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exporting DataFrame\n",
    "\n",
    "# Export comma-separated variable file\n",
    "export = filtered.to_csv('filtered.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
